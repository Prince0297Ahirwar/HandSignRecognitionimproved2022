{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e400fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 #opencv\n",
    "import numpy as np\n",
    "import os   #helps with path\n",
    "from matplotlib import pyplot as plt #to use plt.imshow()\n",
    "import time              #to measure time between frames \n",
    "import mediapipe as mp   \n",
    "mpDraw=mp.solutions.drawing_utils\n",
    "mpHands=mp.solutions.hands\n",
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB because by default opencv use bgr but we need rgb for mediapipe to process image\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results\n",
    "def draw_landmarks(image, results):\n",
    "    if results.multi_hand_landmarks:\n",
    "        for num, handsLms in enumerate(results.multi_hand_landmarks):\n",
    "            mpDraw.draw_landmarks(image,handsLms, mpHands.HAND_CONNECTIONS,\n",
    "                             mpDraw.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
    "                             mpDraw.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2) )\n",
    "def get_label(index,results):\n",
    "    label = None\n",
    "    for idx, classification in enumerate(results.multi_handedness):\n",
    "        if classification.classification[0].index == index:\n",
    "            label = classification.classification[0].label\n",
    "#         print(index,idx,label)\n",
    "    if label:\n",
    "        return label\n",
    "    else:\n",
    "        if index == 1:\n",
    "            return get_label(0,results)\n",
    "        elif index == 0:\n",
    "            return get_label(1,results)\n",
    "        else:\n",
    "            return label\n",
    "def extract_keypoints(results):\n",
    "    hands = [np.zeros(21*3),np.zeros(21*3)]\n",
    "    if results.multi_hand_landmarks:\n",
    "        for num, handsLms in enumerate(results.multi_hand_landmarks):\n",
    "            label = get_label(num,results)\n",
    "            if label == 'Right':\n",
    "                hands[0] = np.array([[res.x, res.y, res.z] for res in handsLms.landmark]).flatten()\n",
    "            if label == 'Left':\n",
    "                hands[1] = np.array([[res.x, res.y, res.z] for res in handsLms.landmark]).flatten()\n",
    "            \n",
    "    return np.concatenate(hands)\n",
    "categories = np.array(['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z','del','space','nothing'])\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense,Flatten\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import tensorflow as tf\n",
    "ACCURACY_THRESHOLD = 0.97\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # print(logs.get('acc'))\n",
    "        # print(logs.get('categorical_accuracy'))\n",
    "        if(logs.get('categorical_accuracy') > ACCURACY_THRESHOLD):\n",
    "            # print(logs.get('acc'))\n",
    "            # print(logs.get('categorical_accuracy'))\n",
    "            print(\"\\nReached %2.2f%% accuracy, so stopping training!!\" %(ACCURACY_THRESHOLD*100))\n",
    "            self.model.stop_training = True\n",
    "\n",
    "# Instantiate a callback object\n",
    "callbacks = myCallback()\n",
    "log_dir = os.path.join('trainLogsdNeuralNetworkATOZ26April')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)\n",
    "mycallbacks = [callbacks,tb_callback]\n",
    "model = Sequential()\n",
    "model.add(Dense(64,activation='relu',input_shape=(15,126)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(categories.shape[0], activation='softmax'))\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model.load_weights('model26April.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6926b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_viz(res, actions,input_frame):\n",
    "    output_frame = input_frame.copy()\n",
    "    if res[np.argmax(res)] > 0.8:\n",
    "        cv2.putText(output_frame,actions[np.argmax(res)], (200,300), cv2.FONT_HERSHEY_SIMPLEX,4, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    return output_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4e3bd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "back = cv2.imread('board1.jpg')\n",
    "back = cv2.resize(back,(600,600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9024cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoriesLatest = np.array(['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z','d',' ','n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a2520e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "sequence = []\n",
    "sentence = []\n",
    "threshold = 0.8\n",
    "time_frame = []\n",
    "cap = cv2.VideoCapture(0)\n",
    "started = False\n",
    "# Set mediapipe model \n",
    "with mpHands.Hands() as hand:\n",
    "    i = 20\n",
    "    j = 26\n",
    "    back2 = cv2.imread('board1.jpg')\n",
    "    back2 = cv2.resize(back,(600,600))\n",
    "    while cap.isOpened():\n",
    "        \n",
    "        board = back\n",
    "        # Read feed\n",
    "        ret, frame = cap.read()\n",
    "        # Make detections\n",
    "        image, results = mediapipe_detection(frame,hand)\n",
    "\n",
    "        \n",
    "        # Draw landmarks\n",
    "        draw_landmarks(image, results)\n",
    "        # 2. Prediction logic\n",
    "        keypoints = extract_keypoints(results)\n",
    "\n",
    "        sequence.append(keypoints)\n",
    "#         print(sequence)\n",
    "        sequence = sequence[-15:]\n",
    "#         print(sequence)\n",
    "        \n",
    "        if len(sequence) == 15:\n",
    "            res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "        #3. Viz logic\n",
    "            if res[np.argmax(res)] > threshold: \n",
    "                casl = categoriesLatest[np.argmax(res)]\n",
    "                if casl != 'n' and (cv2.waitKey(1) & 0xFF == ord('v')) :\n",
    "                    cv2.putText(back2,casl, (i,j), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                    if i <= 20 and  started:\n",
    "                        j = j + 26\n",
    "                    i = (i + 20)%500\n",
    "                    if i == 0:\n",
    "                        i = 20\n",
    "                    started = True\n",
    "\n",
    "            # Viz probabilities\n",
    "            board = prob_viz(res, categories,board)\n",
    "        # Show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "        cv2.imshow('viz',board)\n",
    "        cv2.imshow('Text Converter',back2)\n",
    "\n",
    "        # Break gracefully\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ad844e",
   "metadata": {},
   "source": [
    "# To print you have to press v and to quit press q multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae6d7cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
